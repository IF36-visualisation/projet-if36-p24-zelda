---
title: "Rapport de projet "
date: "2024-05-01"
output:
  html_document:
    theme: cosmo
editor_options: 
  markdown: 
    wrap: 72
---

# Projet : Analyse exploratoire d'un jeu de données d'un ensemble de titres présents sur les plateformes Youtube et Spotify

## Introduction

Dans le cadre de l'unité d'enseignement IF36 de l'Université de
Technologie de Troyes, nous entreprenons ce projet d'analyse
exploratoire d'un dataset choisi pour mettre en pratique nos
connaissances en data visualisation.

### Jeu de Données

Les données utilisées dans ce projet de data visualisation sont des
informations sur des chansons publiées sur Spotify et Youtube. Nous
avons accès à des informations générales sur chaque titre comme
l'artiste et l'album ou le single dont il est issu, ainsi que des
attributs comme le tempo, la duration ou encore la danceabilité. Notre
jeu de données peut être répartit en trois sous-groupes : les
informations générales sur le titre, les informations liées à Spotify
(nombre de streams, URI,...) et les informations liées à Youtube (nombre
de vues, nombres de likes, chaîne youtube,...).

Les données ont été collectées sur la plateforme Kaggle. Mais le dataset
ne contenait pas les dates de sortie des chansons, ce qui est une
information très importante. Nous avons donc utilisé l'identifiant
unique de chaque chanson (URI) pour récupérer sa date de sortie grâce à
l'API Spotify et la bibliothèque 'spotifyr' de R.

### Motivations

Nous avons choisi ce jeu de données du fait de la diversité et richesse
des données. Le dataset comprend 19064 lignes, chaque ligne représentant
une chanson d'artistes variés à travers le monde. Les 26 variables
présentes pour chaque chanson offrent une richesse d'informations,
incluant des données générales plus textuelles sur chaque titre comme le
nom de la chanson et l'artiste. Mais ce qui nous a particulièrement plu
sont les informations statistiques sur les plateformes Spotify et
Yotube, qui nous permettront de faire une comparaison entre les deux
plateformes. Enfin, le dataset comporte des données sur les attributs
musicaux de chaque chanson (danceabilité, énergie, tonalité, volume,...)
sous forme de coefficients ou autre valeurs numériques que l'ont a
trouvé très pertinent à analyser.

La musique est un élément central de la culture populaire, touchant un
large public. Analyser les données musicales permet non seulement
d'explorer des tendances et des comportements sur les plateformes
populaires comme Spotify et Youtube, mais aussi de répondre à des
questions d'intérêt général sur la musique, comme :

-   Quels sont les attributs musicaux des chansons les plus streamées ou
    les plus vues ?

-   Y a-t-il une corrélation entre les streams Spotify et les vues
    YouTube ?

-   Quels genres ou artistes sont les plus populaires ?

Nous avons tous utilisé Spotify ou Youtube pour écouter de la musique,
ce qui rend le sujet non seulement pertinent mais aussi personnellement
intéressant. En travaillant sur ce projet, nous pouvons combiner notre
passion pour la musique avec nos compétences techniques en data science,
ce qui rend l'expérience d'apprentissage à la fois enrichissante et
motivante.

## Problématique

**Comment les caractéristiques musicales et les métriques d'engagement
des chansons publiées sur Spotify et YouTube influencent-elles leur
popularité et leur consommation sur ces plateformes de streaming, et
quelles tendances peuvent être dégagées de ces données en termes de
temporalité, d'attributs musicaux et de comportement des utilisateurs
?**

Nous avons centré notre analyse autour de certains axes d'analyse pour
répondre à cette problématique :

-   **Influence des caractéristiques musicales** : Analyse des attributs
    des chansons (danceabilité, énergie, etc.) sur leur popularité.

-   **Temporalité** : Impact de la date de sortie des chansons sur leur
    nombre de streams et de vues.

-   **Comparaison des plateformes** : Relation entre les métriques
    d'engagement sur Spotify et YouTube.

-   **Consommation des singles vs. albums** : Préférences des
    utilisateurs pour différents types de publications.

-   **Effet des caractéristique supplémentaires (featuring, musique
    officielle et/ou sous license)** : Impact des collaborations, de
    l'officialité et des licenses sur la popularité des titres.

-   **Evolution des tendances** : Changements dans les attributs des
    chansons au fil du temps.

## Collecte et Préparation des Données

### Importation des modules

Nous utilisons des librairies non inhérentes au R basique dans notre
analyse explorative. Les librairies/packages que nous chargeons font
partie du Tidyverse.

```{r}
# Uncomment the lines if you need to install a package before :
# install.packages("readr")
# install.packages("dplyr")
# install.packages("tidyr")
# install.packages("stringr")
# install.packages("tibble")
# install.packages("ggplot2")
# install.packages("patchwork")
# install.packages("ggforce")
# install.packages("tidyverse")
# install.packages("cluster")
# install.packages("factoextra")

library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)
library(ggplot2)
library(patchwork)
library(ggforce)
library(tidyverse)
library(cluster)
library(factoextra)
```

### Chargement des données depuis le fichier CSV

Notre jeu de données est stocké dans un fichier CSV (Excel). Nous devons
importer les données dans notre code pour les transformées en
'dataframe' (type de variable en R) afin de pouvoir utiliser des
fonctions de R et de nos librairies du Tidyverse pour 'Explorer' nos
données.

```{r}
# Nous travaillons avec le fichier ayant le chemin suivant : "/data/dataset_if36"
dataset_if36 <- read.csv('data/dataset_if36.csv')
```

### Séparation de la date en année en mois et en jour

La date étant sous format chaine de caractère , cette transformation
permettra de faciliter les analyses liées à l'évolution du temps.

```{r}
#en R , les doubles crochet[[]] permettent d'accéder aux élements d'une liste et non d'un vecteur[]
#sapply est une fonction en R permettant d'appliquer une fonction à chaque élément d'un vecteur
df <- dataset_if36 %>%
  mutate(date_split = strsplit(date, split = "-"),
         annee = as.double(sapply(date_split, "[", 1)),
         mois = as.double(sapply(date_split, "[", 2))) %>%
  select(-date_split) %>%
  filter(!is.na(annee) & !is.na(Stream) & !is.na(Views)) %>%
  filter(is.finite(Stream) & is.finite(Views)) %>%
  filter(annee!=0)


df_sorted <- df %>%
  filter(annee!=0)%>%
  arrange(annee, mois)

```

Maintenant que nos données sont chargées, elles sont prêtes pour
l'analyse.

## Analyse

Afin de facilité la compréhension et la répartition des tâches, nous
avons organisé notre analyse par question.

### Question 1:

[***La date de sortie d'un titre a-t-elle un effet sur son nombre
d'écoutes total sur les deux plateformes ?***]{.underline}

[*Sous-question :*]{.underline} ***Est-ce que l'échantillon de titres du
dataset est composé majoritairement de titres qui sont 'populaires'
indépendamment du temps ?***

-   On s'attend à ce que : plus un titre a été publié il y a longtemps,
    plus il a de views/streams.

-   Ou à l'inverse, la date de publication n'a pas une grande
    corrélation avec le nombre d'écoutes et donc on peut dire que ce
    nombre d'écoute est purement lié à la popularité du titre.

##### Selection des colonnes qui nous intéressent pour cette question et transfer dans un nouveau dataframe 'df_q1'

```{r}
df_q1 <- df %>%
  select(date, annee, mois, Stream, Views, Likes)

#Transformation du type de la colonne 'date' de chr à date
df_q1$date <- as.Date(df_q1$date)

head(df_q1)
```

##### Création d'une colonne représentant le nombre total d'écoutes d'un titre indépendamment de la plateforme

```{r}
df_q1 <- df_q1 %>%
  mutate(ecoutes_totales = Stream + Views)

# Supprimer les lignes avec des valeurs manquantes dans la colonne 'date'
df_q1 <- df_q1[!is.na(df_q1$date), ]


head(df_q1)
```

##### Analyse de la distribution des titres du jeu de données en fonction de l'année

```{r}
df_q1 %>%
    ggplot(aes(x = annee)) +
    geom_histogram(binwidth = 1,  alpha = 0.7,
                   color = "lightblue", fill = "lightblue") +
    scale_y_continuous(expand = expansion(mult = c(0, 0))) +
    scale_x_continuous(breaks = seq(min(df_q1$annee), max(df_q1$annee), by = 2)) +
    labs(x = "Année",
         y = "Count",
         title = "Distribution des titres du jeu de données en fonction de l'année de publication") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
```

```{r}
# Aggregate data by year and create the new category
df_q1_agg <- df_q1 %>%
    mutate(annee_group = ifelse(annee < 2016, '1918-2015', as.character(annee))) %>%
    count(annee_group)

# Create the pie chart
df_q1_agg %>% 
    ggplot(aes(x = "", y = n, fill = annee_group)) +
    geom_bar(width = 1, stat = "identity") +
    coord_polar(theta = "y") +
    scale_fill_brewer(palette = "Paired") +
    geom_mark_hull(aes(filter = annee_group == "2022",
                        label = '2022',
                        description = 'Environ 1/5 des titres sortis en 2022'),
                   fill = NA,
                   color = NA) +
    labs(x = NULL,
         y = NULL,
         fill = "Année",
         title = "Distribution des titres du jeu de données en fonction de l'année \nde publication") +
    theme_minimal() +
    theme(axis.text.x = element_blank(),
          axis.ticks = element_blank(),
          panel.grid = element_blank())
```

##### Analyse de la distribution des titres du jeu de données en fonction du nombre d'écoutes

```{r}
df_q1 %>%
    ggplot(aes(x = ecoutes_totales)) +
    geom_histogram(bins = 60, alpha = 0.7,
                   color = "lightgreen", fill = "lightgreen") +
    scale_y_continuous(expand = expansion(mult = c(0, 0))) +
    scale_x_continuous(labels = scales::number_format()) +
    labs(x = "Année",
         y = "Count",
         title = "Distribution des titres du jeu de données en fonction du nombre d'écoutes") +
    theme_minimal()
```

##### Tracer du Nombre total d'écoutes en fonction de l'année de publication

```{r}
# Use factor() to convert a numeric variable into a discrete variable
df_q1 %>%
  ggplot(aes(x = factor(annee), y = ecoutes_totales)) +
  geom_point(alpha = 0.1, color = "darkcyan") +
  scale_y_continuous(labels = scales::number_format()) +
  stat_summary(aes(group = 1), fun = mean, geom = 'line', colour = 'orange', alpha = 0.7) +
  stat_summary(aes(group = 1), fun = median, geom = 'line', colour = 'yellow', alpha = 0.7) +
  labs(x = "Année", y = "Nombre total d'écoutes", title = "Ecoutes totales par année de publication") +
  coord_trans(y = 'log') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
```

```{r}
# Find the range of the y-axis to use for both plots
y_limits_stream <- range(df_q1$Stream, na.rm = TRUE)
y_limits_view <- range(df_q1$Views, na.rm = TRUE)
shared_y_limits <- range(y_limits_stream, y_limits_view)

# Create the stream plot
stream_plot <- df_q1 %>%
  ggplot(aes(x = factor(annee), y = Stream)) +
  geom_point(alpha = 0.1, colour = "darkcyan") +
  scale_y_continuous(labels = scales::number_format(), limits = shared_y_limits) +
  stat_summary(aes(group = 1), fun = mean, geom = 'line', colour = 'orange', alpha = 0.7) +
  stat_summary(aes(group = 1), fun = median, geom = 'line', colour = 'yellow', alpha = 0.7) +
  labs(x = "Année", y = "Nombre de Streams / Vues", title = "Streams par année de publication") +
  coord_trans(y = 'log') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))

# Create the view plot
view_plot <- df_q1 %>%
  ggplot(aes(x = factor(annee), y = Views)) +
  geom_point(alpha = 0.1, colour = "darkcyan") +
  scale_y_continuous(labels = NULL, limits = shared_y_limits) +
  stat_summary(aes(group = 1), fun = mean, geom = 'line', colour = 'orange', alpha = 0.7) +
  stat_summary(aes(group = 1), fun = median, geom = 'line', colour = 'yellow', alpha = 0.7) +
  labs(x = "Année", y = NULL, title = "Vues par année de publication") +
  coord_trans(y = 'log') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))

# Use the patchwork package to display the plots together
stream_plot + view_plot
```

##### Même graph mais en regroupant par décennie pour plus de lisibilité

```{r}
# Créer une nouvelle variable 'decennie' représentant la décennie
df_q1$decennie <- as.factor((as.integer(df_q1$annee) %/% 10) * 10)

# Use factor() to convert a numeric variable into a discrete variable
# Créer le diagramme en boîte avec ggplot2
df_q1 %>%
  ggplot(aes(x = factor(decennie), y = ecoutes_totales)) +
  geom_boxplot(color = "darkcyan", fill = "lightblue") +
  scale_y_continuous(labels = scales::number_format()) +
  labs(x = "Décennie", y = "Nombre d'écoutes total", title = "Ecoutes totales par décennie") +
  coord_trans(y = 'log10') +
  theme_minimal()
```

#### Analyse

Nous avons utilisé un diagramme en boîte à moustache (box and whisker
plot) car nous avons discrétisé le temps par année et que nous voulions
nous concentrer sur la distribution statistique des valeurs pour chaque
année afin d'en extraire des tendances (si il en existe). Ce graph est
pertinent car il synthétise bien nos valeurs discrètes et facilite la
recherche d'une relation entre la date de publication d'un titre et son
nombre d'écoutes total.

Nous pouvons voir que nos écoutes totales sont plutôt équilibrées en
moyenne car nos boîtes à moustaches se trouvent au même niveau en
ordonnée et ont une taille et une forme plutôt similaires. On remarque
aussi qu'il semble que le 1er quartile et la médiane de nos boîtes sont
confondus presque systématiquement. Nous pouvons en déduire que notre
dataset est échantilloné sur des titres qui ont un nombre minimal
d'écoutes totales. Ce serait donc seulement des titres assez écoutés et
donc 'populaires'.

Comme nous en avions fait l'hypothèse, les titres datant d'avant Spotify
et Youtube qui sont représentés dans ce dataset sont ceux qui sont
encore écoutés aujourd'hui et qui sont encore 'populaires' (des chansons
intemporelles comme celles des *Beatles* ou de *Queen* par exemple).

Ainsi, parmis les titres de notre dataset qui sont tous 'populaires'
dans une certaine mesure, nous avons des titres 'extrêmement populaires'
que nous voyons représentés comme les "points outliers" sur nos
graphique (en magenta).

Nous pouvons remarquer de manière assez flagrante que plus nous avançons
dans le temps, plus ces titres 'outliers' sont nombreux et ont un nombre
d'écoutes total important. Notre interprétation est qu'avec la
démocratisation grandissante des moyens de partager l'information (la
musique en faisant partie) vers un grand public, il devient de plus en
plus facile pour des chansons de devenir très populaires et ce très
vite. La notion de "tubes du moment" ou de "chansons qui font le buzz"
que nous connaissons tous aujourd'hui créée des titres qui représentes
ces valeurs 'outliers' avec des nombres d'écoutes pharamineux dans notre
graphique.

En explorant cette question, nous avons pensé à une autre approche que
nous pourrons développer plus tard. Nous pourrions créer des nouvelles
colonnes dans notre dataframe 'df_q1' calculant le taux d'écoute annuel
d'un titre (nombre d'écoutes total / nombre d'années depuis publication)
pour en visualiser la distribution.

### Question 2:

Existe t'il une relation entre le nombre de streamings Spotify ainsi que
le nombre de vues sur Youtube ?

-   On s'attend à ce que les chansons plus 'vieilles' aient plus de vues
    totales sur Youtube car Youtube existe depuis plus longtemps.

-   Cependant on s'attend à ce que les chansons plus 'récentes'
    (publiées après Spotify) aient plus de streams totaux sur Spotify
    car il semblerait que Spotify tend à remplacer Yotube pour l'écoute
    de musique depuis sa création (hypothèse qu'on pourra essayer de
    vérifier par l'analyse aussi)

##### Récupation des données du nombre de stream avant et après 2008

```{r}
#total des vues et stream de musiques par années
stream_views_annee <- df_sorted %>%
  group_by(annee)%>%
  summarise(stream=sum(Stream), view=sum(Views))


#chanson  avant 2008
stream_view_2008 <- df_sorted %>%
  select(Views, Stream, annee, mois)%>%
  filter(annee<2008)

#chanson après 2008
stream_view_2009 <- df_sorted %>%
  select(Views, Stream, annee, mois)%>%
  filter(annee>2008)
```

##### Nuage de point sensé représenter la relation entre le nombre de vues et le nombre de stream

```{r}

#représentation des nuages de point avant et après 2008
plot1 <- ggplot(stream_view_2008, aes(x = Stream, y = Views)) +
  geom_point(color = "blue")+geom_smooth()+
  labs(title="relation between Stream end Views before 2008")+
  theme(plot.title = element_text(size = 8.5))

plot2 <- ggplot(stream_view_2009, aes(x = Stream, y = Views)) +
  geom_point(color = "blue")+geom_smooth()+
  labs(title="relation between views and stream from 2008")+
  theme(plot.title = element_text(size = 8.5))


grid.arrange(plot1, plot2,  nrow = 2)



```

```{r}
#comparaison annuelle entre le nombre de vues et le nombre de stream

ggplot(stream_views_annee)+geom_line(aes(x=annee, y=stream), color="blue")+
  geom_line(aes(x=annee, y=view), color="red")+
  scale_color_manual(values = c("Stream" = "blue", "View" = "red"))+
  scale_x_continuous(breaks = seq(1913, 2023, by = 10))

```

#### Analyse

les deux nuages de point représentent la relation entre le nombre de
stream sur Spotify et le nombre de vues sur youtube pour les chansons
sorties avant et après 2008. Comme on peut le voir , que se soit avant
ou après l'année 2008 qui est l'année à laquelle spotify a été créé , il
existe bien une relation qui tend vers la linéarité entre le nombre de
stream sur spotify et le nombre de vues sur youtube.

On peut également observer un changement entre les deux nuages de
points. en effet à près 2008, la relation est un peu moins linéaire et
on a un peu plus de point en dessous de la droite ce qui rejoint notre
hypothèse selon laquelle les chancons les plus récentes sont plus
streamées sur spotify que visionnées sur Youtube.

Enfin grace au lineplot qui permet de visualiser l'évolution annuelle du
nombre de vues sur youtube et du nombre de stream sur spotify on peut
voir que pour les chanson sorties à partir de 2010, on a une
augmentation du nombre d'écoute sur spotify par rapport à youtube.

### Question 5:

On peut faire l'analyse pour le nombre d'écoutes total, le nombre de
vues (Yt) et le nombre de streams (Spot.).

Variables : 'Streams', 'Views', 'Likes', 'Comments'

Objectif : Relation avec valeurs discrètes.

Hypothèses :

On suppose qu'on pourra repérer un seuil de nombres d'écoutes à partir
duquel la quantité de like et/ou commentaires augmentent fortement. En
bref, le signal à partir de ce seuil passerait de linéaire à
exponentiel. Cette hypothèse vient du fait que nous supposons qu'à
partir de cette valeur seuil, il y a assez d'engouement pour un titre
pour qu'il "fasse le buzz". On a pensé à cette valeur seuil car les
algorithmes de recommandation de Youtube cherchent à "faire buzzer" des
vidéos (du peu que nous connaissons de ces algorithmes du côté
utilisateur).

##### Utilisez des nuages de points pour visualiser les données et analyser la relation entre stream et like

```{r}
ggplot(dataset_if36, aes(x=Stream, y=Likes)) +
  geom_point(alpha=0.5) +
  ggtitle("Relationship between Streams and Likes") +
  xlab("Streams") +
  ylab("Likes")
```

##### Utilisez des nuages de points pour visualiser les données et analyser la relation entre stream et Comments

```{r}
ggplot(dataset_if36, aes(x=Stream, y=Comments)) +
  geom_point(alpha=0.5) +
  ggtitle("Relationship between Streams and Comments") +
  xlab("Streams") +
  ylab("Comments")
```

##### Utilisez des nuages de points pour visualiser les données et analyser la relation entre Views et Likes

```{r}
ggplot(dataset_if36, aes(x=Views, y=Likes)) +
  geom_point(alpha=0.5) +
  ggtitle("Relationship between Views and Likes") +
  xlab("Views") +
  ylab("Likes")
```

##### Utilisez des nuages de points pour visualiser les données et analyser la relation entre Views et Comments

```{r}
ggplot(dataset_if36, aes(x=Views, y=Comments)) +
  geom_point(alpha=0.5) +
  ggtitle("Relationship between Views and Comments") +
  xlab("Views") +
  ylab("Comments")
```

#### Analyse

Selon notre conjecture, une fois que le Stream ou la View atteint une
certaine valeur, les données peuvent croître de façon exponentielle.
Cependant, selon le nuage de points, la relation entre Stream et View,
Like et Comment est plus linéaire qu'exponentielle.J’ai donc d’abord
essayé d’utiliser une relation linéaire

##### linéaire stream et like

```{r}
ggplot(dataset_if36, aes(x=Stream, y=Likes)) +
  geom_point(alpha=0.5) +
  geom_smooth(method="lm", color="blue") +
  ggtitle("Relationship between Streams and Likes") +
  xlab("Streams") +
  ylab("Likes")
```

##### linéaire stream et comments

```{r}
ggplot(dataset_if36, aes(x=Stream, y=Comments)) +
  geom_point(alpha=0.5) +
  geom_smooth(method="lm", color="red") +
  ggtitle("Relationship between Streams and Comments") +
  xlab("Streams") +
  ylab("Comments")
```

##### \# linéaire views et likes

```{r}
ggplot(dataset_if36, aes(x=Views, y=Likes)) +
  geom_point(alpha=0.5) +
  geom_smooth(method="lm", color="blue") +
  ggtitle("Relationship between Views and Likes") +
  xlab("Views") +
  ylab("Likes")
```

##### linéaire views et comments

```{r}
ggplot(dataset_if36, aes(x=Views, y=Comments)) +
  geom_point(alpha=0.5) +
  geom_smooth(method="lm", color="red") +
  ggtitle("Relationship between Views and Comments") +
  xlab("Views") +
  ylab("Comments")
```

#### Analyse

D'après l'image générée, il est facile de juger que la relation entre le
stream,view et like,comment est complètement linéaire. Quant à Like, je
vérifierai ensuite si une relation exponentielle peut être affichée une
fois que stream ou view atteignent une certaine valeur.

Pour les likes et stream, sélectionnez les données supérieures à 1e+09
pour essayer d'analyser. #filtered_streams_data \<-
dataset_if36[dataset_if36\$Stream \> 1e9, ]

```{r}
# ggplot(filtered_streams_data, aes(x = Stream, y = Likes)) +
# geom_point(alpha = 0.5) +
# geom_smooth(method = "nls", formula = y \~ a \* exp(b \* x),
# method.args = list(start = list(a = 1, b = 0.01)), color = "blue") +
# ggtitle("Relationship between Streams and Likes") +
# xlab("Stream") +
# ylab("Likes")
```

Le code signale une erreur, indiquant que le modèle ne correspond pas à
la distribution réelle des données.

Pour les likes et views, sélectionnez les données supérieures à 1e+09
pour essayer d'analyser. \#"filtered_data \<-
dataset_if36[dataset_if36\$Views \> 1e9, ] \# ggplot(filtered_data,
aes(x=Views, y=Likes)) + \# geom_point(alpha=0.5) + \#
geom_smooth(method="nls", formula=y \~ a \* exp(b \* x), \#
method.args=list(start=list(a=1, b=0.01)), color="blue") + \#
ggtitle("Relationship between Views and Likes") + \# xlab("Views") + \#
ylab("Likes") Le code signale une erreur, indiquant que le modèle ne
correspond pas à la distribution réelle des données.

Ainsi, notre hypothèse est invalide, il existe une relation linéaire
entre stream et likes,stream et comment, views et likes, ainsi que views
et comment.

### Question 7:

Est-ce qu'on peut reconnaître un artiste / un album par une combinaison
d'intervalles pour chaque attribut ?

Variables : 'Artist', 'Album', attributs

Objectif : Relation + Comparaison + Distribution avec valeurs continues
(attributs) et nominales (artistes, albums).

analyse : Quand nous parlons de « reconnaître » ou « identifier » un
artiste par les attributs, nous pensons immédiatement à la
classification hiérarchique. Il y a beaucoup de attributs qui décrire le
style de musique dans notre jeu de données choisi :
"Danceability","Energy","Key","Loudness","Speechiness","Acousticness","Instrumentalness","Liveness","Valence","Tempo".
Il est logique de faire d’abord un Analyse en composantes principales
pour rendre un représentation 2D possible.

```{R}
data <- read.csv("data/dataset_if36.csv")
selected_data <- data %>% select(Danceability, Energy, Key, Loudness, Speechiness, Acousticness, Instrumentalness, Liveness, Valence, Tempo)

scaled_data <- scale(selected_data)
pca_result <- PCA(scaled_data, scale. = TRUE)
```

Pour analyse le résultat, nous visualisons la contribution des
composantes principales :

```{R}
# L’inertie des cps
fviz_eig(pca_result)
ggsave("pca_loadings_plot.png", plot = last_plot(), width = 8, height = 6, dpi = 300)
![inertie](https://imgur.com/8VAmUdX.png)
```

Les deux première composantes représentent environ 45 % d'inertie, nous
pouvons donc dire que cette représentation n'est pas très idéal. Nous
regardons ensuite le cercle de corrélation :

```{R}
# Cercle des corrélations
fviz_pca_var(pca_result, col.var = "contrib", col.ind = "cos2", repel = TRUE)
ggsave("pca_contrib_plot.png", plot = last_plot(), width = 8, height = 6, dpi = 300)
![cercle](https://imgur.com/xocg4eJ.png)
```

```{R}
# Appliquer la classification hiérarchique sur le résultat de l'ACP
pca_scores <- as.data.frame(pca_result$x)
dist_mat <- dist(pca_scores[, 1:2], method = "euclidean")
hc <- hclust(dist_mat, method = "ward.D2")

rect.hclust(hc, k = 3)
clusters <- cutree(hc, k = 3)
clustered_data <- cbind(selected_data, Cluster = clusters)
write.csv(clustered_data, "clustered_data.csv")

clustered_data <- cbind(clustered_data, PC1 = pca_scores[, 1], PC2 = pca_scores[, 2])

#nuage des points
ggplot(clustered_data, aes(x = PC1, y = PC2, color = factor(Cluster))) +
  geom_point() +
  labs(title = "CAH sur PC1 et PC2")
![nuage des points](https://imgur.com/curmszd.png)
```
